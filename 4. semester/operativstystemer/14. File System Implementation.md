Random access files allow direct access to specific records using an index, record number, or key. Record Ordering. Sequential access files store records in a specific order, usually the order in which they were added to the file. Random access files do not have any specific order of storing records.

Therefore Index is random-access and the linked and sequential is sequential.

![[ch14-2023.pdf]]

Partition with a filesystem is a volume
volume control block -> metadata for the filesystem
File control block -> meta data for the files


# What a file-system contains
## Layered approach
Each layer is responsible for doing some logic.

## Contains
* boot-control block
* volume control-block
Number of free blocks in memory, size of blocks, free FCB (file control block) counter, FCB-pointers
* Directory structure  (per file system)
holds information for the INODES (numbers, names). 
* Per-file FCB
contains the information about the file. 

## Directory implementation
[[ch14-2023.pdf#page=14]]

## Cache
### mount table
### in-memory directory-structure cache
holds information about the recent directories visited.

### system-wide open-file table
contains a copy to all the open files, holds the FCB of the files and also some more information

### per-process open-file table
contains pointers to the appropriate
entries in the system-wide open-file table, as well as other information,
for all files the process has open


## Open a file
First search the system-wide open-file table if it is already opened, then we can just make a copy pointer to this and store it in the `per-process open-file table` , the pointer to this is then returned as a `file descriptor/handle`, which contatins information about the file. This operation will also increment numbers such as how many processes has this file open.

When a process closes the file, the per-process table entry is removed, and
the system-wide entryâ€™s open count is decremented. When all users that have
opened the file close it, any updated metadata are copied back to the disk-based
directory structure, and the system-wide open-file table entry is removed

When the files are closed it decrements the `system-wide open-file table` and if the process does not have file handle more it is removed from the `per-process open-file table` and written to disc.


## Memory allocation
### contiguous-strategy
try to allocate the memory in a contiguous-manor, however can external fragmentation, and also internal-fragmentation, can use best-fit, first-fit...  Have to know a file size at allocation time, which may not be known. If too large internal-fragmentation is increased. Can then use and `extent` which is allocating more blocks, when necessary.

### Linked allocation
![[Pasted image 20230424094808.png]]
A file is an initial block of memory, where the last bytes (for the pointer) is then used to point somewhere else in the memory. This allows no external-fragmentation. The problem is that some space is used for storing the pointer, and also that we cannot do a sequential search and have bad random access. 
requires a storage device
read, and some require an HDD seek. Consequently, it is inefficient to support
a direct-access capability for linked-allocation files.

We then use `clusters` which will combine multiple blocks, maybe 4 blocks, to be the smallest memory unit to be worked with, as then the pointer will use less memory overall in the system, and also making the sequential seach faster since the logical to physical mappings of the memory is done less. But this will increase the internal-fragmentation.

Problem again for this linked-allocation is that if a pointer gets damaged we dont know what is pointed at. Could add addtional info, but cause more overhead to the method.

#### FAT
![[Pasted image 20230424095724.png]]
This table is at the start of the volume, and each entry holds the entry of the next block to be read, until an `end-of-file` value is read. Will result in many seeks, as we index through the table and grab the blocks.

This is a method of linked-allocation and is used in MS-DOS


### indexed allocation
Have he a block which has pointers to all the blocks which are needed to read this file. This solves the **direct-access**-problem which the linked-allocation has to deal with. However if use an entire block for indexes, and a pointer is only 4 bytes with a block size of 4096 bytes, there will be a lot of internal-fragmentation. 

If need to store large files, we can link together blocks of pointers. Can use multi-level indexing, where a block points to other blocks of pointers.

With 4,096-byte blocks,
we could store 1,024 four-byte pointers in an index block. Two levels of
indexes allow 1,048,576 data blocks and a file size of up to 4 GB .

Combined scheme.


### Which to use
These are used in combination. Fx can use contiguous-memory for files which requires instant access, as we can easily index into the next block from the start of the block. And for sequential access can use linked-allocation, as we cannot do instant access with linked-allocation, where we have to maybe pass through _i_ -blocks to get to the i'th block.

Some systems combine contiguous allocation with indexed allocation by
using contiguous allocation for small files (up to three or four blocks) and auto-
matically switching to an indexed allocation if the file grows large. Since most
files are small, and contiguous allocation is efficient for small files, average
performance can be quite good.


#### Drawbacks for linked-allocation:
additional memory use for the pointer (not as much as indexed tho)
only sequential access

#### drawbacks for sequential
external fragmentation

#### drawbacks for indexed
internal fragmentation, as the index block stored for each file has to also be a block-size large.


## free-space management
Keep track of which blocks are free to be used
### methods
#### free spacelist


#### bit-vector (very bad)

#### linked list
slow if not using 
##### grouping
the first n entries contains pointers to m-free blocks, and the next to just regular free blocks

#### counting
store the address with how many contiguous blocks are free from this address. Can be stored in a tree structure for efficiency.

### deletion
when deleting the blocks usually keep their contents, which are ready to be overwritten.


# IMPORTANT
## cache
it is worth to cache open-files in the `system-wide open-file table`, as this will grant significant speed up


-----
# File system structure
Resides on secondary storage
+ Provided user interface to storage, mapping logical to physical
+ Provides efficient and convenient access to disk by allowing data to be stored, located retrieved easy

Device driver for the disk controls physical hardware

## Layered approach
[[ch14-2023.pdf#page=5]]
See slides after for explanation

Its slow since it is layered and need to pass each layer. Advantage is abstraction of what each layer has to do.


# Different File systems
many file systems exists, each with their own attributes
- FAT: old, but widely used - many OSes has the drivers to mange these. Not efficient. Used fx in USB-sticks, the file system is FAT since again most OSes has the drivers, and we dont care much about the speed.
- UFS: UNIX file system, open source
- ZFS: large scale systems, efficient.


# (Disk) File system Operations
## Contains
[[ch14-2023.pdf#page=9]]
* boot-control block
* volume control-block
Number of free blocks in memory, size of blocks, free FCB (file control block) counter, FCB-pointers
* Directory structure (per file system)
holds information for the INODES (numbers, names).  
* Per-file FCB
contains the the information about the file.  [[ch14-2023.pdf#page=10]]

# (In-memory) File System structures
[[ch14-2023.pdf#page=12]] This show the core idea of the file system in memory. Each process has open-file table, which points to the system-wide open-file table which points to blocks in memory. These are cached once they are touched, pulling them into memory, and if accessed again it is much faster.

The request for a file is done in userpace, kernel space then handles the finding of the specific block and goes into the actual secondary storage.

# Directory Implementation
How to store the FCB's: Linear List or Hash Tables

# Allocation Methods
When a new file comes, and requires some blocks to be allocated to it

## Contiguous
see slides

## Linked allocation
Blocks has pointers to the next block. Have a pointer to the beginning block and maybe to the last block, or if you meet a block which has pointer to null instead of a block. Better for external fragmentation

If one block breaks, you wont find the next block. Here contiguous is better as an example.
Use 4 bytes for each pointer if using 32bit pointers.

### Used in FAT
![[Pasted image 20230424095724.png]]

## Indexed allocation
[[ch14-2023.pdf#page=24]] 
Limitation is that you may only have $\frac{block\ size}{pointer\ size}$ entries, but can do multi level, pointing to another index block with fx the first entry.

## Performance
Depends on file access type. and if NVM or HDD. In NVM using Linked is fine since no head to move. But worse for HDD. 
If sequential: contigous or linked
if random: Indexed or contigous (can just put the offset in)

# Extent based systems
If you know you will need more blocks, you could fx make an extent that is 20 blocks big. This is a possibility to do in theses systems. this will make the external fragmentation less.

# Free space management
Each sector can just contain a bit whether in use or not. This is call a **bit-vector**

## Linked list of free space
Dont use the extra bits for the "in use bit", but have a head which points to the next sector free and so fourth.

### Grouping
the first n entries contains pointers to m-free blocks, and the next to just regular free blocks

### counting
Store the block with how many contiguous blocks are free from this block.

## Space Maps
For big storage. Used in ZFS

# Trimming unused blocks

# Efficiency and performance
+ Cache information, fx the FCB
+ read-ahead, free-behind

# Recovery
Having a energy buffer, such that all the writes can be done, meaning less chance of the file-system being in an inconsistent state. 
Making backups of a state

## Log structured systems
Each update to the metadata in something in the file system is a **transaction**, which is kept in a **log**. The transactions are stored sequentially in very fast expensive NVM, and something the transactions in the log are asynchronously executed. When a system crashes it still has to execute the transactions in the logs. When user inserts a transactions, it is from the users perspective seen as tho it has been executed.

## Snapshots
Storing a state of the system which can be rolled back to.
Often used in Virtualization
But can also be done in regular file-system.

**Implemented in WAFL**
More efficient than what you would think, does not store all information

