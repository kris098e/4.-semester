![[ch06-2023.pdf]]
Basicly needs synchronization as all machines today uses multiprocessors and each core will also try to simulate parallelism by during concurrency. 
# Keywords
* software based solutions to critical sections does not scale well with modern architecture
* Hardware based involves
	* memory barriers, compare and swap, test and set, atomic variables
* mutex locks
	* spin locks
	* semaphores
		* binary and counting
			* uses sleeping and wakeup system calls
				* signal() and wait()
	* Monitors
		* high level form of synchronization
		* array of condition variables
			* condition variables are basically just binary semaphores
* Lockfree implementations
* Some tools works better for some system-loads, i.e the use should vary based on this knowledge
* liveness
* priority inversion

# Race conditions 
* race conditions
	* this is why we need synchronization tools
		* could illustrate the execution when two processes call to count++ at the same time
	* Lock when accessing shared data


# Critical section problem
* Critical section (of a program) problem
	* Entry sections, exit section and remainder/code section. When entering grab lock, no one else can be in the block when not having the lock, exit releases the lock.

## Peterson's solution
* peterson's solution (software based solution, no help from hardware)
	* works for two processes
		* **mutual exclusion** (no other processes in the block)
			* in **petersons**, the proof is that only one of the processes may have the turn value set to itself. If both try to update them at the same time, at least one of the processes will be successful with it statement. 
		* progress (progress is happening for the processes)
			* in **petersons** when a process enters its mutual exclusion area, then it will have its turn. The other process is waiting for either of the conditions, and as the process in its executes a statement allowing the process into its unsafe area, it will enter and make progress.
		* Bounded waiting (a process cannot wait indefinitely)
			* Look at the fact that both processes enters their critical section
## Memory barriers
Memory barriers (set in between code such that load and stores before this code has been made when moving on from the memory_barrier().)
	* If the compiler sees data dependencies between two assignments then it may reorder the code for optimizations. **Peterson's solution does not work with incorrect placement of the assignments** Could put memory barrier between the two assignments such that we are sure of the ordering of the statements

## Hardware instructions
* Need assembly instructions that cannot be interrupted (atomic)
		* the other instructions are then build on top of these.
* `test_and_set` and `compare_and_swap`-instructions (**THEESE ARE HARDWARE ASSEMBLY INSTRUCTIONS that are done atomicly.**)
	* `compare and swap()`-instruction is used to implement fx the mutex lock, and is a strong tool to use. Its also used to implement `atomic variables`.
```c
void increment(atomic int *v)
{
	int temp;
	do {
		temp = *v;
	} while (temp != compare_and_swap(v, temp, temp+1));
}
```

1. `compare_and_swap(v, temp, temp+1)`: The `compare_and_swap` function is used to perform an atomic compare-and-swap operation. This operation checks if the value of `v` is still equal to `temp` and, if so, updates the value of `v` to `temp+1`. Otherwise, it does not modify the value of `v`.
    
2. `temp != compare_and_swap(v, temp, temp+1)`: The result of the `compare_and_swap` operation is compared with the original value `temp`. If the two values are not equal, it means that another thread modified the value of `v` between the read and the compare-and-swap operation. In this case, the loop continues, and the process is repeated until the atomic increment is successfully performed.



* introduce locks
	* variation of compare_and_swap that introduce bounded waiting

**Need to initialize the lock to be = 0**
```c
boolean test_and_set(boolean *target) {
	boolean rv = *target;
	*target = true;

	return rv;
}

do {
	while (test_and_set(&lock))
	; /* do nothing */
	
	/* critical section */
	lock = false;
	/* remainder section */
} while (true);
```

**Need to initialize the lock to be = 0**
Basicly just swaps the value, if lock = 0 then unlocked, and if expected = 0 then lock it. Next that check will see that the lock is 1 and will always return 1 until the lock is changed back to 0.
```c
int compare and swap(int *value, int expected, int new value) { 
	int temp = *value;
	if (*value == expected){
		*value = new value;
	}
	return temp;
}

while (true) {
	while (compare and swap(&lock, 0, 1) != 0)
	; /* do nothing */
	/* critical section */
	lock = 0;
}
/* remainder section */
```

Bounded-waiting mutual exclusion with compare_and_swap()
```c
while (true) {
	waiting[i] = true;
	key = 1;
	while (waiting[i] && key == 1)
		key = compare and swap(&lock,0,1);
	waiting[i] = false;
	
	/* critical section */
	
	j = (i + 1) % n;
	while ((j != i) && !waiting[j])
		j = (j + 1) % n;
		
	if (j == i)
		lock = 0;
	else
		waiting[j] = false;
	/* remainder section */
}
```
## Mutex locks
**spin-locks** used most frequently in operating systems, however should only be used when the expected spin time is less than 2 context switches, as this is what will be either way be wasted if blocking the process.
**regular locks**
**Semaphores** 
```c
wait(S) {
	while (S <= 0 )
	; // busy wait
	S--;
}

signal(S) {
	S++;
}
```

**Monitors**
* mutex lock
	* `acquire` and `release` atomicly (calls when lock is unavailable blocks the process)
		* both operations are atomic
	* queue of processes that wants to access the lock
		* calls to `acquire` and `release` must be done atomicly, i.e the `compare_and_swap()` instruction can be used.
* lock may be implemented with `spinlocks()` with while loop, busy doing nothing, but does many checks each second. Wasted CPU-time
	* can use this if the expected lock is held for a short time
		* else go to sleep (but pays context switch time. i.e if CPU time > context switch, go with context switch else spin)
* semaphores (low level synchronization, if want to implement synchronization, better off using higher level languages that already has implented something with locks and atomic)
	* Just an integer variable
	* signal and wait. signal increases the variable by 1, wait decreases by 1. Signals something is available, and the waiting graps the task and decrease the variable. If the variable is 0, no tasks are available
		* `sleep()` sleep yourself
		* `wakeup()` other process wakes you up
	* The call to `wait()` and `signal()` must be done _atomicly_, such that race conditions do not happen. However as theese two instructions are short, it does not lower efficency of the program so much as spin locking. By using semaphores we move the busy waiting to the critical section of the application program, instead of the entry block, as we just call the semaphore and let it handle the `block()` and `wakeup()`. 
	* **Counting semaphores**: used for a finite amount of resources which is a shared data structure
	* **binary semaphores**: basically just a mutex lock
	* Implementation can be seen on page 275 in the book of the call to sleep and wakeup
		* the semaphores is a struct with a `list of processes & integer-value`. When calling to wait and nothing is there, sleep and put the process to the list. Signal will wake up another process from the list.
* monitors (not important to know about, just know it can be implemented with mutex locks and semaphores)
	* uses variables for which we can call `x.wait()` and `x.signal()` i.e dont have a waiting-que, but can have an array of condition variables, which if one process calls `x.wait()` then another process can free it by calling `x.signal()`. 
		* this means fx use `Condition self[5]` can then calf `self[3].wait()` and another calls `self[3].signal()`
	* Condition variables
		* `wait()` doesnt behave as `wait()` in semaphores. 
			* may produce no side effects.
		* signal and wait
		* signal and continue 
	* can be implemented with semaphores and mutex locks

## Program state
* Liveness
	* are in a system state, no matter where we are in a system state, one event can always be triggered => live event
* **quassi life** => if we can reach an event. Quassi life may not be live
* We say that a set of processes is in a deadlocked state when every process in the set is waiting for an event that can be caused only by another process in the set
	* event is live if can get other events, if fx stuck in a infinite loop its not live.

## Priority Inversion
Can only happen if there are 3 or more priorities.
Meaning if we have 3 priorities L M H, and L holds a resource that H needs, and M preempts L, then H must wait for a process with lower priority. This is avoided by `priority-inheritance protocol`, where if a lower priority process uses a resource a higher processes resource, it gains the priority of the higher priority process for the time it contains this resource.

## Evaluation
can create lock-free algorithms using only CAS-instructions. Based on the degree of the locks being contented, the more contention the faster a lock-free algorithm will be - but they are also harder to implement.

Mutex locks are better simpler and require less overhead than semaphores, but semaphores can be used for when the program has multiple resources. Using monitors often results in big overhead for the program, based on their implementation - but they are easy to use.



