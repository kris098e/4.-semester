A page is an index into the page table.

page tabels have page to frame mapping: index | frame number. Then frame number with offset gives the correct physical address. The page offset is not stored in the page table as this is just overhead.



if hierachical page tables, outer index goes to inner page table index which has the frame number.

# Introduction
As many processes are to be executed in parallel, i.e many processes in main memory at the same time, we need methods to handle this.
Most methods needs hardware support

## Basic Hardware
Before the CPU can operate on data, it must be moved to main memory - or it can also be in registers. Accessing registers are very fast, accessing caches are fast, access to main memory is slower than cache but faster than many times faster than disc. memory accesses are usually the bottleneck, remember that a core can switch to another hardware thread while reading off some memory, minimizing the wait-time

Operating system must be able to separate processes from each other. Can implement it with `base+limit` registers, knowing the legal address space for the process address space. The CPU then compares every memory access to see if it is in the legal range. 
Not legal = trap in CPU and generate seg-fault.

Loading of the `base+limt` can only be done by the operating system
![[Pasted image 20230604100404.png]]

## Address Binding
Process can be put anywhere in the main-memory, i.e it can be totally random.

When addresses are to be fixed in memory, the compiler will put fx the variable `Count` in a fashion of **14 bytes from the beginning of the module** and the linker or loader will bind the logical address to the absolute address. 

depending on if we know where the program will reside in memory:
+ know it at **compile time**: Can make the mappings at compile time. If the address space change, we have to recompile.
+ **Load time**: Compiler generates relocateable code. Final binding at load time. 
+ **Execution time**: If the process can be moved during its execution, need special scheme for doing this.
![[Pasted image 20230604101207.png]]

## Logical Versus Physical Address Space
Address generated by the CPU = logical address OR virtual address
In memory (as seen by the memory unit) = physical address.

Mapping from logical address to physical address is done by the **memory-management unit**. 
In a simple case, the MMU is just adding some number to the logical address. I.e if virtual address is 0, bu the physical is 14000, just add the numbers.
User program always only uses logical addresses.


## Dynamic Loading
Some of the program is only loaded when needed or when called. Stored in a relocatable format on the disc. When loaded, the program address table is update to reflect the change

## Dynamic-Linking and Shared libraries

As we dont want to copy fx the entire stdlib in C into process, as this would increase the executeables size very much, we point the processes by the dynamic-linking to where the code can be found in main memory, which can then be used by multiple processes. We then use dynamic loading if the process is not in main memory. If the  library which is dynamicly-linked updates, all of the processes receives the updates.

# Contiguous memory allocation
allocate main memory efficient
memory divided into user and OS parts.
Most place OS in high memory locations

In this scheme they are placed one after the other.

## Memory Protection
dont want processes to access each others memory
Compare the mapped address to see if it is between `base register` and `base + limit`.


## Memory Allocation
Memory is a set of blocks with varying sizes
When processes enter, the OS determines which block size it will be allocated.
If not enough space, put into `wait-queue` or reject.
If the released memory is adjacent to other free blocks, they are merged into a larger block.

Can use 
* First fit: allocate to the first hole
* Best fit: allocate to smallest hole that is big enough. Must search entire set of free blocks
* Worst Fit: allocate to largest free block. Must search entire set of free blocks

First fit faster than both, and also almost equally as good as best fit to storage utilization

## Fragmentation
First fit and best fit will generate more external fragmentation than worst fit.
External fragmentation. Free blocks are scattered all over, not many contiguous free blocks.
First fit with optimization will usually generate an external fragmentation of 1/3 of the memory, rendering this part useless.  
Can use **compaction**, but is quite expensive. Moving all used blocks towards a contiguous allocation, and the unused into the other part of the memory. Another solution is to use **Paging**, where the physical memory is not contiguous but appears to be so in virtual memory.

Internal: unused memory in each allocated block. Fixed by having varying sized blocks. Keeping track of this measure gives more overhead than just not to do it. 

# Paging
where the physical memory is not contiguous but appears to be so in virtual memory. Solves external fragmentation


## Basic Method
**frames**: break physical memory in blocks of fixed size 
**Pages**: blocks of same size as frames

Every address generated by the CPU has the format `page number | page offset`. Page number is index into the page table, translating this into the corresponding frame, using the offset to index into the frame. This is done by MMU
**Page table**: is per process.
Still have internal-fragmentation, as if the process does not need the all of the last frame allocated to it, space is wasted. Expect a half frame to not be used for each process. Therefore small frames are desirable
Typical page size are 4KB or 8KB, need to have large frames as transferring more bytes as one from disc is faster than multiple smaller.
If a page table is $2^{32}$ bits long, it can access that many physical frames, and if a frame size is $2^{12}$ bits then a page table can access $2^{44}$ bytes which is 16TB. But additional information are kept, such as offset and other control bits 
If a process needs n pages, which each maps to 1 frame, then n frames are allocated to the process.

The OS has a **frame table** which holds information for each frame, if they are allocated and if they are, to which processes


## Hardware Support
The PCB must, in its data structure, store a pointer to the page-table. And the frames in physical memory for which it is mapped to, must be correct.
Simple case would be to store the page tables in dedicated registers, but this will increase context switch time, as these must be loaded when switching, but it is very efficient. Can be used when the page table is small.
For **large** page tables, as most page tables today holds $2^{20}$ entries, a dedicated register `page-table base register` points to the page table. Context switching only requires this register to be changed.

### Translation Look-Aside Buffer
**TLB** hit rates are usually sitting around 99%.

First get entry in main memory, can then get the desired data from the frame. Meaning we need 2 memory accesses.
Implement then a small cache with a page-number to fram-number store, which is searched before using the page-table. Meaning no memory accesses. Usually have 32-1024 entries. Some architectures even have multiple levels of TLB.

The MMU checks in the TLB for an entry for the page-number, if found -> can access the frame. This is a **TLB-hit**. 
If not found, access memory to find the frame in the **page-table**. Then when found it is added to the TLB. **TLB-miss**.

**Address-space identifier**. The TLB can contain addresses from old processes as it is bounded to the CPU-core. Therefore it must also keep track of if the process asking to access this page which is cached, is actually in the correct address space. If not keeping track of this information, the TLB must be **flushed** each time a new process enters

**TLB hit ratio**. Fx takes 10 nanoseconds to access TLB and check it. If this misses have to go to main memory. Going to main memory takes 10 nanoseconds + 10 nanoseconds, both checking TLB and then memory.![[Pasted image 20230604120912.png]]
When having multiple TLB levels, hit ratios are to be analyzed aswel.

The TLB is hardware implemented, so is of little concen to the OS-implementers and designers.

## Protection
protection bits in page table, to read-write or read only
Illegal attempts generates traps, which are handled by OS.
valid-invalid bit. Based on if the frame is in the processes address space.

## Shared Pages
Share pages with other processes. Fx same pages to `libc`. 
Some systems implement shared memory via paging.

# Structure of the Page Table
For example, consider a system with a 32-bit logical address space. If the
page size in such a system is 4 KB (2 12 ), then a page table may consist of over
1 million entries (2^20 = 2^32 /2^12). 
**This is very hard to index into, to see if the page is actually stored in memory, which is why we want it reduced. Also wanting the need for only storing the outer page table in memory, and on demand load in the page-tables for each processes**

## Hierarchical Paging
p1 is the index into the outer page-table, where we can find the inner page table. We can then use p2 to index into the inner page table.
![[Pasted image 20230604125040.png]]
![[Pasted image 20230604125415.png]]
![[Pasted image 20230604125547.png]]

However if using 64bit addresses, the hierarchical paging is also inappropriate, as we would have to have page-table to page table to page table mappings. Fx 4 levels would look like
![[Pasted image 20230604125732.png]]
Meaning that we would still have 2^32 bytes in size in the outer page table, having 4GB in main memory at all times is not good.

## Hashed Page Tables
Have hash table where the page index is the key, run through hash function. Store the page number with the frame number and the pointer to the next page to frame pair, to handle collisions. 
![[Pasted image 20230604131836.png]]

For 64bit uses page tables where multiple pages are stored with multiple frames.??

## Inverted Page Tables
Usually the page table has way more entries than what there actually are frames. Meaning the page tables are almost never filled out completely. **Only one page table in the system**.
In this case there are no duplicates and each page maps to a frame in memory. Each entry also holds information of which process that owns the page
![[Pasted image 20230604132546.png]]
Uses address-space identifiers to ensure a process gets correctly mapped to the physical frame corresponding to the logical address.
The table contains `<process-id, page-number, offset>.`
When searched it is given the pID and page-number and will return the `<frame,offset>` if found, or else illegal access. Cannot have multiple different virtual addresses to the same frame, which is opposite to the others, where it is a rule to have page table for each process.

Implemented via hash-tables, for not needing to go through all of the other processes pages.


## Oracle SPARC Solaris

# Swapping
Backing store, to store a process in memory temporarily 

## Standard Swapping
Move the entire process, i.e write the entire PCB to the backing store, and if there are multiple threads, write these aswel

It is used because if we encounter an waiting or nonactive process, it can be swapped allowing the OS to overcommit to processes, simulating extra memory. When the processes becomes ready again, they can be swapped back

## Swapping with Paging
Swapping is rarely used because it is slow moving entire processes back and fourth though RAM and backing store

Instead of moving entire processes, only move a couple of pages. **Page out** refers to moving a page to backing store, and **page in** is moving it back.

## Swapping on Mobile Systems
flash memory / SSD
constraint on memory and components
**iOS**: ask processes to terminate to free up memory, and if needed be terminated.
**Android:** terminate processes, but write program state to flash memory, allowing for quick restart

# Intel 32- and 64-bit Architectures


## IA-32 Architecture
Split into segmentation and paging

### Segmentation
![[Pasted image 20230605083037.png]]

## Paging
Has two page sizes, 4KB and 4 MB
![[Pasted image 20230605083234.png]]
![[Pasted image 20230605083252.png]]
Flag entry in the outermost page-table (called the **Page directory**) tells if the page points to a 4MB or 4MB page.  If the  page is not in memory, an entry in the page directory tells if it is invalid, and the other 31 bits specifies the disk location of the table, which then can be put into memory.

## x86-64
Can address $2^{64}$ bytes, however only supports 48 bit virtual addressing
page sizes
* 4KB
* 2MB
* 1GB
4 levels paging hierarchy.
![[Pasted image 20230605084124.png]]

# ARMv8 Architecture
ARM processors are more used in smartphones and tablets.
![[Pasted image 20230605085236.png]]


# LECTURE
# Logical memory address
Given to memory addressing control unit to refer to physical memory address
Page tables = mapping from logical memory address to physical

logical memory addresses are generated by the CPU

# Operating system
lives in main memory

# access
process may not access something outside of its own memory??

# Static and dynamic loading of libaries
If finding a libary online already compiled it will probably be slower, since it isnt compiled to your architecture

# contigious memory allocation
a process lives in base to $base + limit$

# dynamic storage-allocation problem
first fit
best fit 
worst fit

according to the process size

# Fragmentation
internel - the memory in the specific block that are used
external - the entire programs memory use

# Paging
logical mem = pages
physical mem = frames

all split into blocks of the same size.

core data structure for mapping pages to frames is a page-table

![[Pasted image 20230322145634.png]]
in a 32 bit architecture, if the block size is of size in (fx $2^{12}=4kB$), i.e we use 12 bits for the offset,  then we have $32-12=20$bits left for the page number.

page number is an ID into the page table 

$2^{20}$ page indexes, which is 1MB for the page table? Each process has its own page-table, so each process needs this much extra memory for the page-table.

## Translation look aside buffer TLB
look example in page

## Memory protection
each process has its own page table?

valid and invalid bits to guard access

## shared paging
dont duplicate libraries

## Page replacement
Different algorithms to use

Or can just select a victim frame and kill it


### FIFO
### LRU
### OPT (cannot be implemented
### Second-chance
### LFU
### MFU


## Thrashing
keep track of how many pages are processes **REALLY** using is used.

# Allocation of memory in kernel
Different that user-mode allocation

## Buddy system
## Slab allocator

# Important
* Page faults happens when the frame we want to access in the physical memory is not in the main memory, then we have to look at the harddisk/SSD or other

* global and local page replacement
* working-set (frames that are in use for a process)
* thrashing
	* If CPU utilization is going down while the sum of working-sets is actually equal to main memory -> start killing processes, ?as thrashing still may be happening?
* 
	