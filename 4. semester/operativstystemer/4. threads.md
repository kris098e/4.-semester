![[ch04.pdf]]
![[Pasted image 20230529131339.png]]

# Read again
The reason why the many-to-one model blocks when the kernel-thread is blocking is due to the LWP which maps all of the threads to the kernel-thread, where the upcall will block all of the threads mapped to the kernel-thread.


# Overview
Threads contains a program counter, stack, thread ID and register set. It shares the process it was spawned from the code/text, data section and other operating-system resources, such as open files and signals.

![[Pasted image 20230529083043.png]]

## Motivation
More lightweight to spawn a thread than a process, due to the fact it shares stuff and address space (what does it truly share?)

**web-server example** spawn a new thread for each request to be served.
Kernel is multithreaded

## Benefits
+ Responsiveness (fx both have UI and a backend for a game. Click button should not make UI wait)
+ Resource Sharing (if using processes and needs shared memory, have to be explicitly handled by programmer, threads already shares with eachother)
+ Economy (threads has less things to context-switch, easier to create because they share memory, dont need to give new memory to this process)
+ Scalability (if coded right, can just spawn more threads to scale better)

# Multicore programming
Notice the distinction between concurrency and parallelism in this discus-
sion. A concurrent system supports more than one task by allowing all the tasks
to make progress. In contrast, a parallel system can perform more than one task
simultaneously

Computers on a single-core system creates the illusion of parallelism by rapidly switching from processes to processes

## Programming Challenges
Need CPU-schedualing algortihms that are more complex

+ Identifying tasks
+ Balance (if some task provides little value compared to others, then it may not be beneficial to create this task)
+ Data splitting (where split on fx the array and when to stop splitting) 
+ Data dependency (synchronization)
+ Testing and debugging (harder, multiple execution paths for the program, may not be able to replicate)

## Types of Parallelism
### Data parallelism
focuses on distributing subsets of the same data
across multiple computing cores and performing the same operation on each
core.
**Also data parallelism if just executing the same code**

fx summing up an array, one thread takes the first half and the next takes the 2nd half

### Task parallelism
involves distributing not data but tasks (threads) across
multiple computing cores.
may still share some data
**Has to execute different code**

fx performing different operations on the array

# Multithreading models
+ user threads
+ kernel threads

## Many-to-One
All user threads for a process maps to the same kernel-level threads

unable to scale well, since if one thread make system-call the entire process will block, due to LWP blocking all threads connected to it due to the **upcall**

## One-to-One
Each user thread is mapped to a kernel-thread.

Only problem is that many kernel-level threads are spawned, which may burden the system. 
Linux and winodws implement this model.


## Many-to-Many
All user threads are mapped to the same number of kernel-threads or less. 
The user can then create as many threads it needs, and the kernel can then make sure that not too many kernel-threads are needed

Hard to implement (how many threads should be created? How to know this?)
Also since the modern hardware comes with more and more cores, limiting the amount of kernel-threads may not be such a good idea.
Today one-to-one is mostly used

#### two-level model
Also uses many-to-many however one thread may explicitly be mapped to a kernel-thread

# thread libraries
The API can be implemented in user-space and in kernel-space. If in user-space, the data structures and functions are in user space and vice versa. If calling a kernel-space implementation, it typically results in a system call.

+ POSIX Pthreads (can be provided as either a user-level or kernel-level library)
+ Windows (API for kernel-level threads)
+ java threads (The JVM is running on the hosts operating system, and therefore it uses the API provided by the operating system)

Variables which are global are in memory is shared amongst all threads. Look at exercise answers.

> Asynchronus threading: the parent continues executing after the child is created, i.e they run concurrently. Therefore little to no data is shared among the processes. Used by responsive UI or servers...

> Synchronous threading: The parent threads waits for all the threads to finish and then joins with them. Fx each thread do something and the parent then combines the result


## Pthreads
Is a specification, not an implementation. Is implemented by the UNIX-type systems, but also implementations via third-party libraries are provided in fx windows

```c
pthread t tid; /* the thread identifier */
pthread attr t attr; /* set of thread attributes */
/* set the default attributes of the thread */
pthread attr init (&attr);
/* create the thread */
pthread create (&tid, &attr, runner, argv[1]);
/* wait for the thread to exit */
pthread join (tid,NULL);
```

attributes, creating the thread, intializing the ID, passing attributes, giving the function for which to start and the parameter for the function. Join on the thread ID.

Pthread join before printing the sum

## Windows threads
Uses `CreateThread()` 
Passed some attributes, where to start, security, stack size, parameter to thread function, which function to start in, initialization of the thread ID .
`WaitForSingleObject()` join before printing the sum

For example, if THandles is an array of thread HANDLE objects of size N , the
parent thread can wait for all its child threads to complete with this statement:
`WaitForMultipleObjects(N, THandles, TRUE, INFINITE);`

## Java Threads
Available for Windows, Linux, macOS and Android. As mentioned before, it uses the thread API in the host.

Classes has to implement the `Runnable interface` and override the `run()`-method 
```java
Thread worker = new Thread(new Task());
worker.start ();
```
Calling `start()` initializes the thread and java will then call `run()` specified in the `Thread`-instance.

If having to wait for multiple, enclose the waiting in a for-loop where each Thread-instace is in an array, each being called `.joing()` on

`Executor`- interface
`Callable`-interface. If implementing this, you can make a thread return something, and then you can call `.get()` on the thread once done. The Class has to override the `call()` method

```java
class Summation implements Callable<Integer>{
	private int upper;
	public Summation(int upper) {
		this.upper = upper;
}
/* The thread will execute in this method */
	public Integer call () {
		int sum = 0;
		for (int i = 1; i <= upper; i++)
		sum += i;
		}
		return new Integer(sum);
	}
	
public class Driver {
	public static void main(String[] args) {
		int upper = Integer.parseInt(args[0]);
		ExecutorService pool = Executors.newSingleThreadExecutor ();
		Future<Integer> result = pool.submit (new Summation(upper));
	}
}
```

# Implicit Threading
Uses a run-time library, where the developers only have to identify the tasks which can be done in parallelism, meaning they don t have to manage the threads themselves, nor the creation. Simplifying greatly, since they only need to identify the tasks

## Thread Pools
Fx in the web-server problem, if each request has to be served by a **new** thread, it has to create this thread each time, and this may also lead to the creation of unlimited threads, which may cause strain to the memory and CPU time (could lead to thrashing fx).

Use thread pools instead. At startup a pool of threads is created, and when receiving a request, a thread is woken up to do this task. If no availability the task is queued.

1. Servicing a request with an existing thread is often faster than waiting to
create a thread.
2. A thread pool limits the number of threads that exist at any one point. This
is particularly important on systems that cannot support a large number
of concurrent threads.
3. Separating the task to be performed from the mechanics of creating the
task allows us to use different strategies for running the task. For example,
the task could be scheduled to execute after a time delay or to execute
periodically.

Can also be scaled such that if less tasks are coming in, less threads are ready thereby not using as much memory.


• LPTHREAD START ROUTINE Function —a pointer to the function that is to
run as a separate thread
• PVOID Param —the parameter passed to Function
• ULONG Flags —flags indicating how the thread pool is to create and man-
age execution of the thread

Windows has the function in their API 
`QueueUserWorkItem(&PoolFunction, NULL, 0);`

Passing a a pointer to the function which should be executed by one of the threads in the pool with a paramaeter and the flags

### java Thread Pools
1. Single thread executor— newSingleThreadExecutor() —creates a pool
of size 1.
2. Fixed thread executor— newFixedThreadPool(int size) —creates a
thread pool with a specified number of threads.
3. Cached thread executor— newCachedThreadPool() —creates
unbounded thread pool, reusing threads in many instances.

```java
import java.util.concurrent.*;
public class ThreadPoolExample {

	public static void main(String[] args) {
		int numTasks = Integer.parseInt(args[0].trim());
		/* Create the thread pool */
		ExecutorService pool = Executors.newCachedThreadPool() ;
		/* Run each task using a thread in the pool */
		for (int i = 0; i < numTasks; i++)
			pool. execute (new Task());
	}
}
/* Shut down the pool once all threads have completed */
```
### Fork Join
Synchronous synchronization waiting for all tasks, which are started to be done.

#### Fork join in java
Divide-and-conquer algorithms

The general logic is
```java
Task(problem)
		if problem is small enough
			solve the problem directly
	else
		subtask1 = fork(new Task(subset of problem)
		subtask2 = fork(new Task(subset of problem)
		
		result1 = join(subtask1)
		result2 = join(subtask2)
		
		return combined results
```
The call to join blocks until the task is finished executing.

The class called upon has to inherit from the `ForkJoinTask`.

sums up all the ints from 1 to SIZE
```java
ForkJoinPool pool = new ForkJoinPool();
// array contains the integers to be summed
int[] array = new int[SIZE];

SumTask task = new SumTask(0, SIZE - 1, array);
int sum = pool.invoke(task);
```
## OpenMP
Open MP is a set of compiler directives as well as an API for programs written in
C, C++, or FORTRAN that provides support for parallel programming in shared-
memory environments

When `OpenMP` encounters the directive `#pragma omp parallel` it creates as many threads as there are cores to execute the task in parallel

```c
#pragma omp parallel for
for (i = 0; i < N; i++) {
	c[i] = a[i] + b[i];
}
```

## Grand Central Dispatch
Developed by Apple for macOS and iOS
run-time library and API, used like OpenMP, only having to specifying the task that can run in parallel.

Has a **serial dispatch**- and **conurrent dispatch-queue** GCD scheduales tasks for run-time execution by placing them on these dispatch ques.
When taken out it is schedualed for execution.

Serial queues are FIFO. Once the process has been taken out it must be executed and finished before another task is schedualed to run. Ensuring sequential execution.

on the concurrent queue they are also removed as FIFO but multiple tasks may ran in parallel.

**There are multiple concurrent dispatch queues**

• QOS CLASS USER INTERACTIVE —The user-interactive class represents
tasks that interact with the user, such as the user interface and event
handling, to ensure a responsive user interface. Completing a task
belonging to this class should require only a small amount of work.
• QOS CLASS USER INITIATED —The user-initiated class is similar to the
user-interactive class in that tasks are associated with a responsive user
interface; however, user-initiated tasks may require longer processing
• QOS CLASS UTILITY —The utility class represents tasks that require a
longer time to complete but do not demand immediate results. This class
includes work such as importing data.
• QOS CLASS BACKGROUND —Tasks belonging to the background class are
not visible to the user and are not time sensitive. Examples include index-
ing a mailbox system and performing backups.

I.e class for user-interaction, which has to be handled quickly but requires small amount of work. executed immediately. Fx getting user input
class for user-initiated, more work than the one above, however it does not have to executed immediately, but faster than the ones below
Utility requires longer time, but doesnt require immediate results. Fx importing data 
Background, not visible to the user and are not time sensitive. fx indexing mailbox or performing backups

Specifying a block in **C, C++ and Objective-C. **
`^ { printf("I am a block"); }`

**in swift**
```swift
let queue = dispatch_get_global_queue
(QOS_CLASS_USER_INITIATED, 0)

dispatch async(queue, { print("I am a closure.") } )
```

The threads are handled by the POSIX threads. It is implemented by the _libdispatch_ libary.

## intel Thread Building Blocks
Library for C++, is cache aware (i.e gives higher priority to threads for which their data may be in the cache memory for faster execution), support for atomic operation, parallel loop structures and mutual exclusion locking.

can use `parallel_for(range, body)`

Again the library will control how many threads are spawned, instead of the programmer having to specify this, while also again emphasizing the need for only having to identify which tasks can run in parallel

# Threading Issues
## fork() and exec() system calls
When calling `fork()` are all threads duplicated or only the one calling? The UNIX systems has two fork() calls specifying if you want to duplicate all or just the one calling.
`exec()` will replace the entire process - including all threads.

If the process calls to `exec()` right after the fork, then only the duplicate the calling thread. If not calling the `exec()` then only duplicate all threads. I.e if the program is replaced, there is no need for the duplication overhead.

## Signal Handling.
may be asynchronous or synchronous
1. A signal is generated by the occurrence of a particular event.
2. The signal is delivered to a process.
3. Once delivered, the signal must be handled.

If a process receives a synchronous signal it has to handle it immediatly. Fx divsion by 0 or seg-fault

if generated by an external event to the process, it receives an asynchronous signal.  Fx. a timer expire or a specific key-stroke

A signal may be handled by one of two possible handlers:
1. A default signal handler
2. A user-defined signal handler

If running a process concurrently, where should the signal be delivered?

1. Deliver the signal to the thread to which the signal applies.
2. Deliver the signal to every thread in the process.
3. Deliver the signal to certain threads in the process.
4. Assign a specific thread to receive all signals for the process.

+ synchronous signals are delivered to the thread causing the problem
+ asynchronous sent to all threads. fx ctrl+c

send signal to a process (sent to the first thread that is not blocking the signal)
`kill(pid t pid, int signal)`

for a specific thread:
`pthread kill(pthread t tid, int signal)`

**windows does not support signal but can emulate them**  via asynchronous procedure calls ( APCs ), send to a thread and are asynchronous

## Thread Cancellation
terminating a thread before it has completed its task

two ways:
1. Asynchronous cancellation. One thread immediately terminates the tar-
get thread.
2. Deferred cancellation. The target thread periodically checks whether it
should terminate, allowing it an opportunity to terminate itself in an
orderly fashion.
3. Disabled (disable the option of being cancelled)

When deleted, which resources to reclaim? Hard with asynchronous as no cleanup, since instant deletion

`pthread_cancel(tID)` is deffered

default is Deferred

threads using `deferred` occurs only when a thread reaches a `cancellation point`. fx `read()` reaches this point when it is blocked and waits for input.
Threads may call to `pthread_testcancel()`, testing there may be some cancel-requests. 
```c
while (1) {
/* do some work for awhile */
. . .
/* check if there is a cancellation request */
pthread testcancel ();
}
```
Pthreads allow a `cleanup handler` to be invoked, which release all resources the thread has accquired during its lifetime

java will use 
```java 
while (!Thread.currentThread(). isInterrupted ()) {
. . .
}
```
and the parent calls `worker.interrupt()` on the Thread-instance

## Thread-Local Storage
Sometimes a thread needs its own data, instead of that of just the parents.
It is not local-variables, as the variables are global to the thread.

+ java: ThreadLocal\<T\> with get and setters
+ pthread key t in Pthreads
+ C: static \_\_Thread 

## Scheduler activation
communication between user and kernel threads.

**LWP** is the data structure used. The user level thread is attached to this while also the kernel-level thread. If the kernel-level thread blocks the LWP also blocks and thereby the user-level thread also blocks.

If 5 reads are called upon, 5 LWPs are needed mapping each thread to a kernel-thread. For a processor with a single-core only 1 LWP is needed.

a technique for communication between the threads **scheduler activation** kernel provides an application with a set of virtual processors (LWPs) The application can then schedule user threads on available LWP. When events happen, the kernel performs an **upcall** which is handled by a **upcall handler**.
Fx. if a kernelthread will block it performs an upcall, and the user-application can then schedule a thread to run on another LWP, when the thread no longer blocks i performs another upcall, meaning the LWP can be used again

# Operating-System examples

## Windows threads
uses one-to-one mapping

+ A thread ID uniquely identifying the thread
+ A register set representing the status of the processor
+ A program counter
+ A user stack, employed when the thread is running in user mode, and a
+ kernel stack, employed when the thread is running in kernel mode
+ A private storage area used by various run-time libraries and dynamic link
libraries ( DLL s)

## Linux threads
`fork()` creates a new process, while `clone()` can take in parameters for what to share with the process.
![[Pasted image 20230529124301.png]]
If all are used, it is like creating a thread. However if none are passed, it is like creating a new process. 
Each process/task/thread has its own `struct task_struct` which has information about the task, specificly it points to the data structures used for the process, i.e for the list of open files, memory ... .  When creating a thread with `copy()` and all flags are passed, it just points to the parents `struct task_struct`. 