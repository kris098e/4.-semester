![[_DM566-2023-part5.pdf]]
[variance computation](https://www.mathsisfun.com/data/random-variables-mean-variance.html)
![[Pasted image 20230314100354.png]]



# Part 1
## Keywords
* random variable associated with the event
	* random variable is not per say an actual variale. Its a function mapping the a sample space, or subset of a sample space, to a number.
* independent events based on random variables
* Expectation/mean
![[Pasted image 20230307103720.png]]

* variance
How much the random variable X (which again is a function, mapping a sample space to a number) differs from the expectation of X (look expecation).
[example](_DM566-2023-part5.pdf#page=25)
> notice that the expectation is multiplied on each summation.

* standard deviation
* covariance
	* how much one variable diverges from its expectation, times the other variable divergence from its expectation
* correlation
![[Pasted image 20230307105046.png]]
since we cannot tell anything, about x from y and vice versa, see the example on figures relevant to each possible coveriance
* median and mean


## Recap
* Random variable
* Expectation
* Variance


# part 2

## keywords
* Probability distrubutions (area under the graph, for which the area under the entire graph is 1)
* probability in infinite sample space
	* infinitely many options => probability of random variable X taking one specific value, is 0.
* Cumulative distrubution function => integral of the function smaller than or equal to a.
	* can also do between a and b i.e $a\leq X\leq b$. Do the integral between.
* Joint distribution
* Uniform distribution
	* The area between a and b is summing up to 1, i.e the probability distribution sums up to 1 between theese, and is 0 elsewhere
		* Can also be used in multi-dimension,fx. the volume of a square in 3d just have to sum up to 1
* Normal distribution
	* If you have multiple random variables that may behave randomly, if we accumulate the sum of theese it will follow the normal distribution
	* Standard normal distribution
	* Geometrical meaning of mean and variance
		* The lower the variance the bigger the peak. because the sum of area on the graph still has to be the same 
	* Can be used in 3d aswel, the **Bivariate Normal Distribution** 
* Standarzing via **z-score**

## recap
* Commulative distribution function (CDF)
	* $Pr(x\leq a)\in[0,1]$
	* $Pr(X\leq+inf)=1$
	* $Pr(a\leq X\leq B)=Pr(X\leq b)-Pr(X\leq a)$


# Part 3
* Data set (design matrix)
* Different interpitation of a single algorithm
	* algebraic: as a vector, calculating the distances
	* statistical/probabilistic
		* EM clustering
			* Cluster is represented by a probabilistic density function
				* fit multiple normal distributions over each cleaster
					* to figure out which cluster the point is part of, set a threshold for the y-value i.e draw a line on the y-axis and decide which x-value has its corresponding y-value high enough to be under some y-value-threshold, and the point must then be under the normal distribution
				* Can then figure out with a probability fx if point b belongs to cluster 1 or cluster 2 with a probabilities. I.e cluster1 = 87%, cluster2 = 20%
			* worse than k-means, when looking into the runtime. Even tho the probablistic approach is fully paralellizable, because there is one step that costs so much
		* Parametric vs Non-parametric Learning [[_DM566-2023-part5.pdf#page=116]]
		* 