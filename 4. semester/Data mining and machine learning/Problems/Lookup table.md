# our own solutions
## Set rules and classification
[[solution01.pdf]]

## (næsten ligegyldig) Apriori, Confidence, Itemsets and Association Rules
[[solution02.pdf]]

## Closed Frequent Itemsets, Apriori, Color Histograms
[[solution03.pdf]]

## Distance Measures, Clustering, Silhouette
[[solution04.pdf]]

## Clustering : k-means and Silhouette, Evaluation of Classifiers, Probability
[[solution05.pdf]]

## Conditional Probability and Bayes’ Theorem, k-Nearest Neighbor Classification
[[solution06.pdf]]

## Bayes Optimal Classifier, Naïve Bayes, Random Variables and Distributions, EM Clustering
[[solution07.pdf]]

## 8. Clustering Algorithms, Density Estimation. Shared NN neighbors, density estimation of DBSCAN
[[8. Clustering Algorithms, Density Estimation]]


## Bayes rule, Desicion-tree, Probability, Outlier Detection
[[11. Bayes rule, Desicion-tree, Probability, Outlier Detection]]

## Decision Tree, Bias-variance trade-of, Linear Discriminant Analysis. BIAS, VARIANCE
[[12. Decision Tree, Bias-variance trade-of, Linear Discriminant Analysis]]

## probability, k-means algorithm, probability and statistics, support vector machine. CDF, PDF
[[13. probability, k-means algorithm, probability and statistics, support vector machine]]

## 15. Probability, Bayes Optimal Classifier, Decision Tree. RANDOM VARIABLE
[[15. Probability, Bayes Optimal Classifier, Decision Tree]]

# Solutions 2022
## DBSCAN properties & density estimation & shared nearest neighbors
[[solution08.pdf]]

## OPTICS & information gain calculation & 
[[solution09.pdf]]
remember that we are looking into the valleys. If it is dense the valley stays low and will be beginning and ending with a high peak

## Hyperplanes calculation and visualitation
[[solution10.pdf]]

## Confidence and support
[[solution11.pdf]]